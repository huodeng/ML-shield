<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.21" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const useChoice = localStorage.getItem('vuepress-color-scheme')
      const systemStatus =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (useChoice === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (useChoice === 'dark' || systemStatus) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <title>安全评估 | ML Security Simulator</title><meta name="description" content="全面的机器学习模型安全性与隐私风险评估平台">
    <link rel="preload" href="/ML-shield/assets/style-DKcZtDkc.css" as="style"><link rel="stylesheet" href="/ML-shield/assets/style-DKcZtDkc.css">
    <link rel="modulepreload" href="/ML-shield/assets/app-C7ybsvO5.js"><link rel="modulepreload" href="/ML-shield/assets/security-assessment.html-Z_ikAi0e.js">
    <link rel="prefetch" href="/ML-shield/assets/index.html-BfRGJcSM.js" as="script"><link rel="prefetch" href="/ML-shield/assets/dataset-upload.html-Cvs7SEcp.js" as="script"><link rel="prefetch" href="/ML-shield/assets/faq.html-tvVS9BmW.js" as="script"><link rel="prefetch" href="/ML-shield/assets/introduction.html-CEQENl6y.js" as="script"><link rel="prefetch" href="/ML-shield/assets/model-analysis.html-BHCPvBfa.js" as="script"><link rel="prefetch" href="/ML-shield/assets/quick-start.html-DBiCr-XJ.js" as="script"><link rel="prefetch" href="/ML-shield/assets/index.html-Cx3Hpt5b.js" as="script"><link rel="prefetch" href="/ML-shield/assets/404.html-CXKdhyXD.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/ML-shield/"><!----><span class="vp-site-name" aria-hidden="true">ML Security Simulator</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/ML-shield/" aria-label="首页"><!--[--><!--[--><!--]--><!--]-->首页<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/ML-shield/guide/" aria-label="教程"><!--[--><!--[--><!--]--><!--]-->教程<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/ML-shield/api/" aria-label="API"><!--[--><!--[--><!--]--><!--]-->API<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="了解更多"><span class="title">了解更多</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="了解更多"><span class="title">了解更多</span><span class="right arrow"></span></button><ul class="vp-navbar-dropdown" style="display:none;"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/ML-shield/faq/" aria-label="常见问题"><!--[--><!--[--><!--]--><!--]-->常见问题<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/ML-shield/about/" aria-label="关于我们"><!--[--><!--[--><!--]--><!--]-->关于我们<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/ML-shield/" aria-label="首页"><!--[--><!--[--><!--]--><!--]-->首页<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/ML-shield/guide/" aria-label="教程"><!--[--><!--[--><!--]--><!--]-->教程<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/ML-shield/api/" aria-label="API"><!--[--><!--[--><!--]--><!--]-->API<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="了解更多"><span class="title">了解更多</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="了解更多"><span class="title">了解更多</span><span class="right arrow"></span></button><ul class="vp-navbar-dropdown" style="display:none;"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/ML-shield/faq/" aria-label="常见问题"><!--[--><!--[--><!--]--><!--]-->常见问题<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/ML-shield/about/" aria-label="关于我们"><!--[--><!--[--><!--]--><!--]-->关于我们<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading active">教程 <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link route-link-active auto-link vp-sidebar-item" href="/ML-shield/guide/" aria-label="ML Security Simulator 平台教程"><!--[--><!--[--><!--]--><!--]-->ML Security Simulator 平台教程<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/ML-shield/guide/introduction.html" aria-label="平台简介"><!--[--><!--[--><!--]--><!--]-->平台简介<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/ML-shield/guide/quick-start.html" aria-label="快速开始"><!--[--><!--[--><!--]--><!--]-->快速开始<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/ML-shield/guide/dataset-upload.html" aria-label="数据集上传"><!--[--><!--[--><!--]--><!--]-->数据集上传<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/ML-shield/guide/model-analysis.html" aria-label="模型分析"><!--[--><!--[--><!--]--><!--]-->模型分析<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link route-link-active auto-link vp-sidebar-item active" href="/ML-shield/guide/security-assessment.html" aria-label="安全评估"><!--[--><!--[--><!--]--><!--]-->安全评估<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/ML-shield/guide/faq.html" aria-label="常见问题"><!--[--><!--[--><!--]--><!--]-->常见问题<!--[--><!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div vp-content><!--[--><!--]--><div><h1 id="安全评估" tabindex="-1"><a class="header-anchor" href="#安全评估"><span>安全评估</span></a></h1><p>本章将详细介绍ML Security Simulator平台提供的安全评估功能，帮助您全面了解模型的安全风险并采取相应的防御措施。</p><h2 id="安全评估概述" tabindex="-1"><a class="header-anchor" href="#安全评估概述"><span>安全评估概述</span></a></h2><p>安全评估是对机器学习模型进行全面的安全性分析，包括对抗鲁棒性、隐私风险和模型可靠性等多个维度。通过安全评估，您可以：</p><ul><li>识别模型中的潜在安全漏洞</li><li>量化不同类型攻击的成功率和影响</li><li>评估防御措施的有效性</li><li>获取安全性提升的建议</li></ul><h2 id="自适应最优超参搜索" tabindex="-1"><a class="header-anchor" href="#自适应最优超参搜索"><span>自适应最优超参搜索</span></a></h2><p>基于贝叶斯优化算法，自动搜索最优超参组合，以提升模型性能和鲁棒性。 参数：学习率，批次大小，训练轮数，正则化强度，噪声强度，梯度裁剪阈值</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment">#超参搜索空间</span></span>
<span class="line">space <span class="token operator">=</span> <span class="token punctuation">[</span></span>
<span class="line">    Real<span class="token punctuation">(</span><span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&#39;lr&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">    Real<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&#39;noise_multiplier&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">    Real<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&#39;max_grad_norm&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">    Categorical<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&#39;batch_size&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 改为离散的batch_size</span></span>
<span class="line">    Integer<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&#39;epoch&#39;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="成员推理攻击检测" tabindex="-1"><a class="header-anchor" href="#成员推理攻击检测"><span>成员推理攻击检测</span></a></h2><p>成员推理攻击是一种常见的隐私攻击方式，可以判断特定数据是否被用于训练模型。</p><h3 id="攻击原理" tabindex="-1"><a class="header-anchor" href="#攻击原理"><span>攻击原理</span></a></h3><p>成员推理攻击基于以下观察：模型对训练数据的预测置信度通常高于非训练数据。攻击者可以利用这一特性，通过分析模型的输出行为，判断特定数据是否属于训练集。</p><h3 id="检测流程" tabindex="-1"><a class="header-anchor" href="#检测流程"><span>检测流程</span></a></h3><ol><li><strong>收集目标模型的预测结果</strong>：用数据集对目标模型进行训练与预测，并输出准确率</li><li><strong>训练影子模型</strong>：使用目标模型框架作为影子模型框架，数量可调整</li><li><strong>构建攻击模型</strong>：根据数据集标签类型数量n，构建n个二分类器，每个二分类器根据影子模型的输出进行二分类（0为非训练数据，1为训练数据），并训练</li><li><strong>评估风险</strong>：用攻击模型对目标模型的预测结果进行二分类，计算准确率</li></ol><h3 id="防御建议" tabindex="-1"><a class="header-anchor" href="#防御建议"><span>防御建议</span></a></h3><ul><li><strong>限制模型输出精度</strong>：降低预测置信度的精度</li><li><strong>使用差分隐私技术</strong>：在训练过程中添加噪声</li><li><strong>实施输出扰动</strong>：对模型输出添加随机扰动</li><li><strong>模型正则化</strong>：使用L2正则化或早停等技术减少过拟合</li></ul><h2 id="防御方法" tabindex="-1"><a class="header-anchor" href="#防御方法"><span>防御方法</span></a></h2><p>Shield平台提供差分隐私防御方法，依赖Opacus技术实现。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 应用差分隐私防御</span></span>
<span class="line">privacy_engine <span class="token operator">=</span> PrivacyEngine<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    netd<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> dataloader <span class="token operator">=</span> privacy_engine<span class="token punctuation">.</span>make_private<span class="token punctuation">(</span></span>
<span class="line">        module<span class="token operator">=</span>netd<span class="token punctuation">,</span></span>
<span class="line">        optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span></span>
<span class="line">        data_loader<span class="token operator">=</span>dataloader<span class="token punctuation">,</span></span>
<span class="line">        noise_multiplier<span class="token operator">=</span>parasm<span class="token punctuation">[</span><span class="token string">&quot;noise_multiplier&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        max_grad_norm<span class="token operator">=</span>parasm<span class="token punctuation">[</span><span class="token string">&quot;max_grad_norm&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="梯度反演攻击" tabindex="-1"><a class="header-anchor" href="#梯度反演攻击"><span>梯度反演攻击</span></a></h2><p>梯度反演攻击是一种利用模型梯度信息的攻击方式，可以还原原始数据。</p><h3 id="攻击原理-1" tabindex="-1"><a class="header-anchor" href="#攻击原理-1"><span>攻击原理</span></a></h3><p>梯度反演攻击（发生在联邦学习中）利用模型的梯度信息，通过最小化重构误差来还原原始数据。</p><h3 id="检测流程-1" tabindex="-1"><a class="header-anchor" href="#检测流程-1"><span>检测流程</span></a></h3><ol><li><strong>收集模型梯度信息</strong>：在训练过程中，记录模型的梯度信息。</li><li><strong>构建重构模型</strong>：使用收集的梯度信息，构建一个重构模型，尝试还原原始输入数据。</li><li><strong>评估重构效果</strong>：通过比较重构数据与原始数据，计算mse,ssim评估重构模型的效果。</li><li><strong>分析风险</strong>：根据重构效果，分析模型面临的梯度反演攻击风险。</li></ol><h3 id="防御建议-1" tabindex="-1"><a class="header-anchor" href="#防御建议-1"><span>防御建议</span></a></h3><ul><li><strong>限制模型输出信息量</strong>：只返回预测类别而非完整的置信度向量</li><li><strong>使用对抗训练增强鲁棒性</strong>：减少模型对输入微小变化的敏感性</li><li><strong>实施输入扰动</strong>：在推理阶段对输入添加扰动</li><li><strong>知识蒸馏</strong>：使用教师模型训练更小的学生模型，减少信息泄露</li></ul><h2 id="防御方法-1" tabindex="-1"><a class="header-anchor" href="#防御方法-1"><span>防御方法</span></a></h2><p>Shield平台提供差分隐私防御方法，依赖Opacus技术实现。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 应用差分隐私防御</span></span>
<span class="line">privacy_engine <span class="token operator">=</span> PrivacyEngine<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    netd<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> dataloader <span class="token operator">=</span> privacy_engine<span class="token punctuation">.</span>make_private<span class="token punctuation">(</span></span>
<span class="line">        module<span class="token operator">=</span>netd<span class="token punctuation">,</span></span>
<span class="line">        optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span></span>
<span class="line">        data_loader<span class="token operator">=</span>dataloader<span class="token punctuation">,</span></span>
<span class="line">        noise_multiplier<span class="token operator">=</span>parasm<span class="token punctuation">[</span><span class="token string">&quot;noise_multiplier&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        max_grad_norm<span class="token operator">=</span>parasm<span class="token punctuation">[</span><span class="token string">&quot;max_grad_norm&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="后门攻击检测" tabindex="-1"><a class="header-anchor" href="#后门攻击检测"><span>后门攻击检测</span></a></h2><h3 id="攻击原理-2" tabindex="-1"><a class="header-anchor" href="#攻击原理-2"><span>攻击原理</span></a></h3><p>在后门攻击中，攻击者通过在部分训练数据中插入后门，使得模型在特定情况下表现出错误的行为。</p><h3 id="检测流程-2" tabindex="-1"><a class="header-anchor" href="#检测流程-2"><span>检测流程</span></a></h3><ol><li><strong>数据集中插入后门</strong>：在训练数据中插入特定的后门触发器，如在minst数据集图片中，右下角插入1个2*2的全1矩阵，将其标签改为0。 2.<strong>训练模型</strong>：使用带有插入后门的数据训练模型。 3.<strong>评估模型表现</strong>：使用测试数据评估模型表现，观察模型在插入后门后是否表现异常，计算准确率asr。</li></ol><h3 id="防御建议-2" tabindex="-1"><a class="header-anchor" href="#防御建议-2"><span>防御建议</span></a></h3><ul><li><strong>数据清洗</strong>：在训练前对数据进行清洗，去除潜在的后门触发器。</li><li><strong>模型监控</strong>：在模型部署后，持续监控模型的预测行为，识别异常。</li><li><strong>使用鲁棒训练方法</strong>：采用鲁棒性更强的训练方法，减少后门攻击的成功率。</li></ul><h2 id="防御方法-2" tabindex="-1"><a class="header-anchor" href="#防御方法-2"><span>防御方法</span></a></h2><p>Shield平台提供差分隐私防御方法，依赖Opacus技术实现。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 应用差分隐私防御</span></span>
<span class="line">privacy_engine <span class="token operator">=</span> PrivacyEngine<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    netd<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> dataloader <span class="token operator">=</span> privacy_engine<span class="token punctuation">.</span>make_private<span class="token punctuation">(</span></span>
<span class="line">        module<span class="token operator">=</span>netd<span class="token punctuation">,</span></span>
<span class="line">        optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span></span>
<span class="line">        data_loader<span class="token operator">=</span>dataloader<span class="token punctuation">,</span></span>
<span class="line">        noise_multiplier<span class="token operator">=</span>parasm<span class="token punctuation">[</span><span class="token string">&quot;noise_multiplier&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        max_grad_norm<span class="token operator">=</span>parasm<span class="token punctuation">[</span><span class="token string">&quot;max_grad_norm&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="可视化分析" tabindex="-1"><a class="header-anchor" href="#可视化分析"><span>可视化分析</span></a></h3><p>平台提供多种可视化工具，帮助您直观理解模型的鲁棒性：</p><ul><li><strong>对抗样本展示</strong>：对比原始样本和对抗样本</li><li><strong>决策边界可视化</strong>：展示模型决策边界的变化</li><li><strong>鲁棒性热图</strong>：不同参数下模型鲁棒性的变化</li></ul><h2 id="综合安全评分" tabindex="-1"><a class="header-anchor" href="#综合安全评分"><span>综合安全评分</span></a></h2><p>平台基于多个维度的评估结果，为模型提供综合安全评分，帮助您快速了解模型的整体安全状况。</p><h3 id="评分维度" tabindex="-1"><a class="header-anchor" href="#评分维度"><span>评分维度</span></a></h3><ul><li><strong>对抗鲁棒性评分</strong>：模型抵抗对抗攻击的能力</li><li><strong>隐私保护评分</strong>：模型防止隐私泄露的能力</li><li><strong>可靠性评分</strong>：模型在各种环境下保持稳定性的能力</li><li><strong>综合安全评分</strong>：基于上述维度的加权平均</li></ul><h3 id="评分解读" tabindex="-1"><a class="header-anchor" href="#评分解读"><span>评分解读</span></a></h3><ul><li><strong>90-100分</strong>：优秀，模型具有很高的安全性</li><li><strong>70-89分</strong>：良好，模型安全性较高，但仍有改进空间</li><li><strong>50-69分</strong>：一般，存在明显的安全风险，需要改进</li><li><strong>0-49分</strong>：较差，存在严重的安全漏洞，需要立即修复</li></ul><h2 id="安全报告生成" tabindex="-1"><a class="header-anchor" href="#安全报告生成"><span>安全报告生成</span></a></h2><p>完成安全评估后，平台可以自动生成详细的安全评估报告，包含以下内容：</p><ol><li><strong>评估摘要</strong>：模型安全性的总体评价</li><li><strong>详细测试结果</strong>：各项测试的具体结果和分析</li><li><strong>风险等级</strong>：不同安全风险的严重程度</li><li><strong>改进建议</strong>：针对发现的问题提供具体改进措施</li><li><strong>可视化图表</strong>：直观展示评估结果</li></ol><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 生成安全评估报告</span></span>
<span class="line"><span class="token keyword">from</span> ml_security <span class="token keyword">import</span> SecurityReportGenerator</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 初始化报告生成器</span></span>
<span class="line">report_generator <span class="token operator">=</span> SecurityReportGenerator<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 生成报告</span></span>
<span class="line">report <span class="token operator">=</span> report_generator<span class="token punctuation">.</span>generate<span class="token punctuation">(</span></span>
<span class="line">    model_name<span class="token operator">=</span><span class="token string">&quot;MyModel&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    assessment_results<span class="token operator">=</span>results<span class="token punctuation">,</span></span>
<span class="line">    output_format<span class="token operator">=</span><span class="token string">&quot;pdf&quot;</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 保存报告</span></span>
<span class="line">report<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">&quot;security_assessment_report.pdf&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="下一步" tabindex="-1"><a class="header-anchor" href="#下一步"><span>下一步</span></a></h2><p>完成安全评估后，您可以：</p><ul><li>根据评估结果优化模型架构和训练过程</li><li>实施推荐的防御措施提升模型安全性</li><li>定期重新评估模型安全性，确保持续的安全保障</li></ul><p>在下一章中，我们将解答使用平台过程中的常见问题。</p></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">最近更新：: </span><time class="meta-item-info" datetime="2025-06-15T09:23:47.000Z" data-allow-mismatch>2025/6/15 17:23</time></div><!----></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link auto-link prev" href="/ML-shield/guide/model-analysis.html" aria-label="模型分析"><!--[--><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span class="external-link">模型分析</span></div><!--]--></a><a class="route-link auto-link next" href="/ML-shield/guide/faq.html" aria-label="常见问题"><!--[--><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span class="external-link">常见问题</span></div><!--]--></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/ML-shield/assets/app-C7ybsvO5.js" defer></script>
  </body>
</html>
