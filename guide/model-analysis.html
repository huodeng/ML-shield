<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.21" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const useChoice = localStorage.getItem('vuepress-color-scheme')
      const systemStatus =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (useChoice === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (useChoice === 'dark' || systemStatus) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <title>模型分析 | ML Security Simulator</title><meta name="description" content="全面的机器学习模型安全性与隐私风险评估平台">
    <link rel="preload" href="/ML-shield/assets/style-DKcZtDkc.css" as="style"><link rel="stylesheet" href="/ML-shield/assets/style-DKcZtDkc.css">
    <link rel="modulepreload" href="/ML-shield/assets/app-C7ybsvO5.js"><link rel="modulepreload" href="/ML-shield/assets/model-analysis.html-BHCPvBfa.js">
    <link rel="prefetch" href="/ML-shield/assets/index.html-BfRGJcSM.js" as="script"><link rel="prefetch" href="/ML-shield/assets/dataset-upload.html-Cvs7SEcp.js" as="script"><link rel="prefetch" href="/ML-shield/assets/faq.html-tvVS9BmW.js" as="script"><link rel="prefetch" href="/ML-shield/assets/introduction.html-CEQENl6y.js" as="script"><link rel="prefetch" href="/ML-shield/assets/quick-start.html-DBiCr-XJ.js" as="script"><link rel="prefetch" href="/ML-shield/assets/index.html-Cx3Hpt5b.js" as="script"><link rel="prefetch" href="/ML-shield/assets/security-assessment.html-Z_ikAi0e.js" as="script"><link rel="prefetch" href="/ML-shield/assets/404.html-CXKdhyXD.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/ML-shield/"><!----><span class="vp-site-name" aria-hidden="true">ML Security Simulator</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/ML-shield/" aria-label="首页"><!--[--><!--[--><!--]--><!--]-->首页<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/ML-shield/guide/" aria-label="教程"><!--[--><!--[--><!--]--><!--]-->教程<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/ML-shield/api/" aria-label="API"><!--[--><!--[--><!--]--><!--]-->API<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="了解更多"><span class="title">了解更多</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="了解更多"><span class="title">了解更多</span><span class="right arrow"></span></button><ul class="vp-navbar-dropdown" style="display:none;"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/ML-shield/faq/" aria-label="常见问题"><!--[--><!--[--><!--]--><!--]-->常见问题<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/ML-shield/about/" aria-label="关于我们"><!--[--><!--[--><!--]--><!--]-->关于我们<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/ML-shield/" aria-label="首页"><!--[--><!--[--><!--]--><!--]-->首页<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link route-link-active auto-link" href="/ML-shield/guide/" aria-label="教程"><!--[--><!--[--><!--]--><!--]-->教程<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><a class="route-link auto-link" href="/ML-shield/api/" aria-label="API"><!--[--><!--[--><!--]--><!--]-->API<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="了解更多"><span class="title">了解更多</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="了解更多"><span class="title">了解更多</span><span class="right arrow"></span></button><ul class="vp-navbar-dropdown" style="display:none;"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/ML-shield/faq/" aria-label="常见问题"><!--[--><!--[--><!--]--><!--]-->常见问题<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/ML-shield/about/" aria-label="关于我们"><!--[--><!--[--><!--]--><!--]-->关于我们<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading active">教程 <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link route-link-active auto-link vp-sidebar-item" href="/ML-shield/guide/" aria-label="ML Security Simulator 平台教程"><!--[--><!--[--><!--]--><!--]-->ML Security Simulator 平台教程<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/ML-shield/guide/introduction.html" aria-label="平台简介"><!--[--><!--[--><!--]--><!--]-->平台简介<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/ML-shield/guide/quick-start.html" aria-label="快速开始"><!--[--><!--[--><!--]--><!--]-->快速开始<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/ML-shield/guide/dataset-upload.html" aria-label="数据集上传"><!--[--><!--[--><!--]--><!--]-->数据集上传<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link route-link-active auto-link vp-sidebar-item active" href="/ML-shield/guide/model-analysis.html" aria-label="模型分析"><!--[--><!--[--><!--]--><!--]-->模型分析<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/ML-shield/guide/security-assessment.html" aria-label="安全评估"><!--[--><!--[--><!--]--><!--]-->安全评估<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/ML-shield/guide/faq.html" aria-label="常见问题"><!--[--><!--[--><!--]--><!--]-->常见问题<!--[--><!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div vp-content><!--[--><!--]--><div><h1 id="模型分析" tabindex="-1"><a class="header-anchor" href="#模型分析"><span>模型分析</span></a></h1><p>本章将详细介绍如何使用ML Security Simulator平台对机器学习模型进行安全性分析，包括对抗攻击分析、隐私风险评估和防御措施验证。</p><h2 id="准备工作" tabindex="-1"><a class="header-anchor" href="#准备工作"><span>准备工作</span></a></h2><p>在开始模型分析前，请确保您已完成以下准备：</p><ol><li>上传待分析的模型（支持PyTorch、TensorFlow格式）</li><li>准备好用于评估的数据集</li><li>了解您希望评估的安全风险类型</li></ol><h2 id="对抗攻击分析" tabindex="-1"><a class="header-anchor" href="#对抗攻击分析"><span>对抗攻击分析</span></a></h2><p>对抗攻击分析模块帮助您评估模型对对抗样本的鲁棒性。</p><h3 id="支持的攻击方法" tabindex="-1"><a class="header-anchor" href="#支持的攻击方法"><span>支持的攻击方法</span></a></h3><div class="attack-methods"><div class="attack-method"><h4>FGSM (Fast Gradient Sign Method)</h4><ul><li>基于梯度符号的单步攻击方法</li><li>攻击公式: x&#39; = x + ε·sign(∇ₓJ(θ,x,y))</li><li>适用场景: 快速生成对抗样本</li></ul><div class="code-block"><pre><code>def fgsm_attack(image, epsilon, data_grad):
    # 收集数据梯度的符号
    sign_data_grad = data_grad.sign()
    # 创建扰动图像
    perturbed_image = image + epsilon * sign_data_grad
    # 添加剪裁以保持[0,1]范围
    perturbed_image = torch.clamp(perturbed_image, 0, 1)
    return perturbed_image</code></pre></div></div><div class="attack-method"><h4>PGD (Projected Gradient Descent)</h4><ul><li>多步迭代的FGSM变体</li><li>在L∞约束空间内进行投影</li><li>攻击强度: 通常比FGSM更强</li></ul></div><div class="attack-method"><h4>CW (Carlini-Wagner)</h4><ul><li>基于优化的攻击方法</li><li>最小化对抗扰动的同时保证攻击成功率</li><li>支持L0/L2/L∞多种距离度量</li></ul></div></div><h3 id="分析流程" tabindex="-1"><a class="header-anchor" href="#分析流程"><span>分析流程</span></a></h3><ol><li><strong>选择攻击方法</strong>：从支持的攻击方法中选择一种或多种</li><li><strong>设置攻击参数</strong>：如扰动大小(ε)、迭代次数等</li><li><strong>运行攻击</strong>：系统将自动生成对抗样本并评估模型性能</li><li><strong>查看结果</strong>：分析攻击成功率、模型准确率变化等指标</li></ol><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 对抗攻击分析示例代码</span></span>
<span class="line"><span class="token keyword">from</span> ml_security <span class="token keyword">import</span> AdversarialAttackAnalyzer</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 初始化分析器</span></span>
<span class="line">analyzer <span class="token operator">=</span> AdversarialAttackAnalyzer<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 配置攻击参数</span></span>
<span class="line">attack_config <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token string">&#39;method&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;FGSM&#39;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&#39;epsilon&#39;</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&#39;norm&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;Linf&#39;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 运行攻击分析</span></span>
<span class="line">results <span class="token operator">=</span> analyzer<span class="token punctuation">.</span>run_attack<span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_data<span class="token punctuation">,</span> attack_config<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 查看结果</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;原始准确率: </span><span class="token interpolation"><span class="token punctuation">{</span>results<span class="token punctuation">[</span><span class="token string">&#39;original_accuracy&#39;</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;攻击后准确率: </span><span class="token interpolation"><span class="token punctuation">{</span>results<span class="token punctuation">[</span><span class="token string">&#39;adversarial_accuracy&#39;</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;攻击成功率: </span><span class="token interpolation"><span class="token punctuation">{</span>results<span class="token punctuation">[</span><span class="token string">&#39;attack_success_rate&#39;</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container warning"><p class="hint-container-title">注意</p><p>对抗攻击分析可能需要较长时间，特别是对于复杂模型和大型数据集。</p></div><h2 id="隐私风险评估" tabindex="-1"><a class="header-anchor" href="#隐私风险评估"><span>隐私风险评估</span></a></h2><p>隐私风险评估模块帮助您识别模型中可能存在的隐私泄露风险。</p><h3 id="支持的评估方法" tabindex="-1"><a class="header-anchor" href="#支持的评估方法"><span>支持的评估方法</span></a></h3><ol><li><strong>成员推理攻击</strong>：判断特定数据是否被用于训练模型</li><li><strong>属性推断攻击</strong>：从模型输出中推断训练数据的敏感属性</li><li><strong>模型反演攻击</strong>：尝试重构训练数据中的敏感信息</li></ol><h3 id="评估流程" tabindex="-1"><a class="header-anchor" href="#评估流程"><span>评估流程</span></a></h3><ol><li><strong>选择评估方法</strong>：根据您关注的隐私风险类型选择评估方法</li><li><strong>配置评估参数</strong>：设置攻击强度、目标属性等参数</li><li><strong>运行评估</strong>：系统将自动执行隐私风险评估</li><li><strong>查看结果</strong>：分析隐私泄露风险程度、攻击成功率等指标</li></ol><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 隐私风险评估示例代码</span></span>
<span class="line"><span class="token keyword">from</span> ml_security <span class="token keyword">import</span> PrivacyRiskAnalyzer</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 初始化分析器</span></span>
<span class="line">privacy_analyzer <span class="token operator">=</span> PrivacyRiskAnalyzer<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 运行成员推理攻击</span></span>
<span class="line">membership_inference_results <span class="token operator">=</span> privacy_analyzer<span class="token punctuation">.</span>run_membership_inference<span class="token punctuation">(</span></span>
<span class="line">    model<span class="token punctuation">,</span> </span>
<span class="line">    train_data<span class="token punctuation">,</span> </span>
<span class="line">    test_data</span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 分析结果</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;成员推理攻击准确率: </span><span class="token interpolation"><span class="token punctuation">{</span>membership_inference_results<span class="token punctuation">[</span><span class="token string">&#39;accuracy&#39;</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;隐私风险评分: </span><span class="token interpolation"><span class="token punctuation">{</span>membership_inference_results<span class="token punctuation">[</span><span class="token string">&#39;risk_score&#39;</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="防御措施验证" tabindex="-1"><a class="header-anchor" href="#防御措施验证"><span>防御措施验证</span></a></h2><p>防御措施验证模块帮助您评估不同防御技术对模型安全性的提升效果。</p><h3 id="支持的防御方法" tabindex="-1"><a class="header-anchor" href="#支持的防御方法"><span>支持的防御方法</span></a></h3><ol><li><strong>对抗训练</strong>：使用对抗样本增强训练，提高模型鲁棒性</li><li><strong>差分隐私</strong>：在训练过程中添加噪声，保护训练数据隐私</li><li><strong>模型蒸馏</strong>：通过知识蒸馏减少模型对对抗样本的敏感性</li><li><strong>特征压缩</strong>：压缩输入特征，减少对抗扰动的影响</li></ol><h3 id="验证流程" tabindex="-1"><a class="header-anchor" href="#验证流程"><span>验证流程</span></a></h3><ol><li><strong>选择防御方法</strong>：根据您关注的安全风险选择适当的防御方法</li><li><strong>配置防御参数</strong>：设置防御强度、噪声级别等参数</li><li><strong>应用防御</strong>：系统将自动应用所选防御方法</li><li><strong>评估效果</strong>：对比防御前后的模型安全性和性能变化</li></ol><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># 防御措施验证示例代码</span></span>
<span class="line"><span class="token keyword">from</span> ml_security <span class="token keyword">import</span> DefenseValidator</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 初始化验证器</span></span>
<span class="line">defense_validator <span class="token operator">=</span> DefenseValidator<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 配置对抗训练防御</span></span>
<span class="line">defense_config <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token string">&#39;method&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;adversarial_training&#39;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&#39;attack&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;FGSM&#39;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&#39;epsilon&#39;</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&#39;epochs&#39;</span><span class="token punctuation">:</span> <span class="token number">10</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 应用防御并评估效果</span></span>
<span class="line">results <span class="token operator">=</span> defense_validator<span class="token punctuation">.</span>apply_and_evaluate<span class="token punctuation">(</span></span>
<span class="line">    model<span class="token punctuation">,</span> </span>
<span class="line">    train_data<span class="token punctuation">,</span> </span>
<span class="line">    test_data<span class="token punctuation">,</span> </span>
<span class="line">    defense_config</span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 查看结果</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;防御前攻击成功率: </span><span class="token interpolation"><span class="token punctuation">{</span>results<span class="token punctuation">[</span><span class="token string">&#39;before&#39;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&#39;attack_success_rate&#39;</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;防御后攻击成功率: </span><span class="token interpolation"><span class="token punctuation">{</span>results<span class="token punctuation">[</span><span class="token string">&#39;after&#39;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&#39;attack_success_rate&#39;</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;防御前准确率: </span><span class="token interpolation"><span class="token punctuation">{</span>results<span class="token punctuation">[</span><span class="token string">&#39;before&#39;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&#39;accuracy&#39;</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;防御后准确率: </span><span class="token interpolation"><span class="token punctuation">{</span>results<span class="token punctuation">[</span><span class="token string">&#39;after&#39;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&#39;accuracy&#39;</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container info"><p class="hint-container-title">信息</p><p>差分隐私是目前最有理论保障的隐私保护技术，但可能会降低模型精度。在实际应用中需要权衡隐私保护和模型性能。</p></div><h2 id="可视化分析" tabindex="-1"><a class="header-anchor" href="#可视化分析"><span>可视化分析</span></a></h2><p>平台提供丰富的可视化工具，帮助您直观地理解分析结果：</p><ol><li><strong>对抗样本可视化</strong>：对比原始样本和对抗样本的差异</li><li><strong>决策边界可视化</strong>：展示模型决策边界的变化</li><li><strong>攻击效果热图</strong>：直观展示不同攻击参数的效果</li><li><strong>防御效果对比图</strong>：对比不同防御方法的效果</li></ol><h2 id="下一步" tabindex="-1"><a class="header-anchor" href="#下一步"><span>下一步</span></a></h2><p>完成模型分析后，您可以：</p><ul><li>查看详细的<a class="route-link" href="/ML-shield/guide/security-assessment.html">安全评估报告</a></li><li>根据分析结果优化模型设计</li><li>应用推荐的防御措施提升模型安全性</li></ul><p>在下一章中，我们将介绍如何解读安全评估报告并采取相应的防御措施。</p></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">最近更新：: </span><time class="meta-item-info" datetime="2025-04-17T04:17:50.000Z" data-allow-mismatch>2025/4/17 12:17</time></div><!----></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link auto-link prev" href="/ML-shield/guide/dataset-upload.html" aria-label="数据集上传"><!--[--><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span class="external-link">数据集上传</span></div><!--]--></a><a class="route-link auto-link next" href="/ML-shield/guide/security-assessment.html" aria-label="安全评估"><!--[--><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span class="external-link">安全评估</span></div><!--]--></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/ML-shield/assets/app-C7ybsvO5.js" defer></script>
  </body>
</html>
